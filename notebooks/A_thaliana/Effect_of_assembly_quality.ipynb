{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73da91d8-f44f-4c23-b8e5-f880eb1f1833",
   "metadata": {},
   "source": [
    "# The effect of assembly quality and sequencing depth\n",
    "This notebook contains the analysis of the effect of assembly quality and sequencing depth on pan-genome results.  \n",
    "The analysis mainly consists of comparing several _A. thaliana_ pan-genomes, constructed with either the de novo (DN) or the map-to-pan (MTP) approach, using different data sets with increasing sequencing depth. Results are compared to a pan-genome constructed from high-quality (HQ) genome assemblies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa7488-7213-43ae-b4ec-a50bbd831fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "from Bio import SeqIO\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8e4c1-3e76-496c-8d7a-813c7296adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.templates.default = \"plotly_white\"\n",
    "colors = ['grey','purple','darkgreen','lightblue','orange']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e932888-fdf4-49b1-a450-77826a008668",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0485218-84a3-4e9d-87a2-920d0c8af5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_dir = \"/groups/itay_mayrose_nosnap/liorglic/Projects/PGCM/output/A_thaliana_pan_genome/de_novo\"\n",
    "mtp_dir = \"/groups/itay_mayrose_nosnap/liorglic/Projects/PGCM/output/A_thaliana_pan_genome/map_to_pan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434b826-02a7-4cdc-9d40-4c95157e02ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# de novo pan-genomes\n",
    "dn_pan_genomes = {\n",
    "    'HQ-assembly': os.path.join(dn_dir, \"HQ_assembly/RESULT\"),\n",
    "    \"full_data\": os.path.join(dn_dir, \"full_data/RESULT\"),\n",
    "    \"x50\": os.path.join(dn_dir, \"x50/RESULT\"),\n",
    "    \"x30\": os.path.join(dn_dir, \"x30/RESULT\"),\n",
    "    \"x20\": os.path.join(dn_dir, \"x20/RESULT\"),\n",
    "    \"x10\": os.path.join(dn_dir, \"x10/RESULT\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec076e5f-b466-4f9f-b19c-16c8d1000ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map-to-pan pan-genomes\n",
    "mtp_pan_genomes = {\n",
    "    'HQ-assembly': os.path.join(mtp_dir, \"HQ_assembly/RESULT\"),\n",
    "    \"full_data\": os.path.join(mtp_dir, \"full_data/RESULT\"),\n",
    "    \"x50\": os.path.join(mtp_dir, \"x50/RESULT\"),\n",
    "    \"x30\": os.path.join(mtp_dir, \"x30/RESULT\"),\n",
    "    \"x20\": os.path.join(mtp_dir, \"x20/RESULT\"),\n",
    "    \"x10\": os.path.join(mtp_dir, \"x10/RESULT\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c4873-44cd-4b46-8bab-8cba5fda98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dir = \"/groups/itay_mayrose_nosnap/liorglic/Projects/PGCM/output/A_thaliana_pan_genome/compare_pan_genomes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e084aa-235f-4a05-9208-a39ea6e4a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# de novo comparison dirs\n",
    "dn_compare = {\n",
    "    \"full_data\": os.path.join(compare_dir, \"DN_HQ_asm_vs_DN_full_data/RESULT\"),\n",
    "    \"x50\": os.path.join(compare_dir, \"DN_HQ_asm_vs_DN_x50/RESULT\"),\n",
    "    \"x30\": os.path.join(compare_dir, \"DN_HQ_asm_vs_DN_x30/RESULT\"),\n",
    "    \"x20\": os.path.join(compare_dir, \"DN_HQ_asm_vs_DN_x20/RESULT\"),\n",
    "    \"x10\": os.path.join(compare_dir, \"DN_HQ_asm_vs_DN_x10/RESULT\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf49850-84ff-4808-ade6-e6008bc5f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map-to-pan comparison dirs\n",
    "mtp_compare = {\n",
    "    \"full_data\": os.path.join(compare_dir, \"MTP_HQ_asm_vs_MTP_full_data/RESULT\"),\n",
    "    \"x50\": os.path.join(compare_dir, \"MTP_HQ_asm_vs_MTP_x50/RESULT\"),\n",
    "    \"x30\": os.path.join(compare_dir, \"MTP_HQ_asm_vs_MTP_x30/RESULT\"),\n",
    "    \"x20\": os.path.join(compare_dir, \"MTP_HQ_asm_vs_MTP_x20/RESULT\"),\n",
    "    \"x10\": os.path.join(compare_dir, \"MTP_HQ_asm_vs_MTP_x10/RESULT\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4cb2e-7458-4157-a26b-dddec3c452e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_path = \"/groups/itay_mayrose_nosnap/liorglic/Projects/PGCM/figs/FINAL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c15dbd-0d47-4398-bf3c-f801b63cefba",
   "metadata": {},
   "source": [
    "## Assembly stats\n",
    "Assemblies are common to the DN and MTP pan-genomes, so no need to present results for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df283f56-53c5-4b52-8e65-4c75549e7df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_order = [\"x10\", \"x20\", \"x30\", \"x50\",\"full_data\", \"HQ-assembly\"]\n",
    "samples = ['An-1', 'C24', 'Cvi-0', 'Eri', 'Kyo', 'Ler', 'Sha', 'TAIR10']\n",
    "n_samples = len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199381e0-660f-4f18-90d1-d00b6548b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_pg_asm_stats = {pg: pd.read_csv(os.path.join(dn_pan_genomes[pg],\"all_samples/stats/assembly_stats.tsv\"),\n",
    "                                    sep='\\t', index_col=0) for pg in pg_order[:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9d997-d588-486f-9431-de324d9d3e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['Input bases', 'Clean bases', '# contigs (>= 0 bp)', 'Total length (>= 0 bp)',\n",
    "               'N50', '% Complete BUSCOs', '% unmapped (Chr0)']\n",
    "for pg in dn_pg_asm_stats:\n",
    "    dn_pg_asm_stats[pg] = dn_pg_asm_stats[pg][keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e062fa-43de-486b-96b6-fe4d265335fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# N50\n",
    "n50_dfs = []\n",
    "for pg in pg_order[:-1]:\n",
    "    tmp = pd.DataFrame(dn_pg_asm_stats[pg]['N50'])\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp.columns = ['sample','N50']\n",
    "    tmp['PG'] = pg.replace('full_data','Full data')\n",
    "    n50_dfs.append(tmp)\n",
    "n50_df = pd.concat(n50_dfs)\n",
    "\n",
    "# Assembly size\n",
    "asm_size_dfs = []\n",
    "for pg in pg_order[:-1]:\n",
    "    tmp = pd.DataFrame(dn_pg_asm_stats[pg]['Total length (>= 0 bp)'])\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp.columns = ['sample','assembly_size']\n",
    "    tmp['PG'] = pg.replace('full_data','Full data')\n",
    "    asm_size_dfs.append(tmp)\n",
    "asm_size_df = pd.concat(asm_size_dfs)\n",
    "\n",
    "# BUSCOs\n",
    "busco_dfs = []\n",
    "for pg in pg_order[:-1]:\n",
    "    tmp = pd.DataFrame(dn_pg_asm_stats[pg]['% Complete BUSCOs'])\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp.columns = ['sample','complete_buscos']\n",
    "    tmp['PG'] = pg.replace('full_data','Full data')\n",
    "    busco_dfs.append(tmp)\n",
    "busco_df = pd.concat(busco_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c363ea8-7b59-4298-9d38-6ae8ff36f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_colors = ['blue','red','green','purple','orange','brown','lightblue','darkgreen']\n",
    "sample_colors = dict(zip(samples, sample_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "n50_df['color'] = n50_df['sample'].map(sample_colors)\n",
    "asm_size_df['color'] = asm_size_df['sample'].map(sample_colors)\n",
    "busco_df['color'] = busco_df['sample'].map(sample_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "n50_median = n50_df.groupby('PG').median().reindex(pg_order[:-2]+['Full data'])\n",
    "asm_size_median = asm_size_df.groupby('PG').median().reindex(pg_order[:-2]+['Full data'])\n",
    "busco_median = busco_df.groupby('PG').median().reindex(pg_order[:-2]+['Full data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354335ca-5e48-4b9d-a5a9-055a46f068e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=3, cols=1,\n",
    "                    shared_xaxes=True,\n",
    "                    vertical_spacing=0.05)\n",
    "\n",
    "for sample in samples[:-1]:\n",
    "    tmp_df = n50_df.query('sample == @sample')\n",
    "    fig.add_trace(go.Scatter(x=tmp_df['PG'], y=tmp_df['N50'], marker_color=sample_colors[sample], mode='markers', name=sample), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=n50_median.index, y=n50_median['N50'], mode='lines', line={'color':'black', 'dash':'dash'}, name='Median'), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=asm_size_df['PG'], y=asm_size_df['assembly_size'], marker_color=asm_size_df['color'], mode='markers', showlegend=False), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=asm_size_median.index, y=asm_size_median['assembly_size'], mode='lines', line={'color':'black', 'dash':'dash'}, showlegend=False), row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=busco_df['PG'], y=busco_df['complete_buscos'], marker_color=busco_df['color'], mode='markers', showlegend=False), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=busco_median.index, y=busco_median['complete_buscos'], mode='lines', line={'color':'black', 'dash':'dash'}, showlegend=False), row=3, col=1)\n",
    "\n",
    "fig.update_yaxes(title_text=\"N50\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Assembly size\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"% complete <br> BUSCOs\", row=3, col=1)\n",
    "fig.update_xaxes(mirror=True, showline=True, linecolor='black')\n",
    "fig.update_yaxes(mirror=True, showline=True, linecolor='black', showgrid=False)\n",
    "fig.update_layout(width=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fde0ea-31be-4991-9059-9ce1d37e8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3_a = os.path.join(figs_path, 'fig3a.pdf')\n",
    "fig.write_image(fig3_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-union",
   "metadata": {},
   "source": [
    "## Gene PAV analysis\n",
    "Analyze the effect of sequencing depth and assembly quality on gene PAV calling and nonreference gene detection.  \n",
    "Each pan-genome was compared to the a pan-genome constructed from HQ assemblies using the same pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-holocaust",
   "metadata": {},
   "source": [
    "### Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DN PAV matrices\n",
    "dn_pav = {\n",
    "    pg :\n",
    "    pd.read_csv(os.path.join(dn_pan_genomes[pg],\"all_samples/pan_genome/pan_PAV.tsv\"), sep='\\t', index_col='gene')\n",
    "    for pg in dn_pan_genomes\n",
    "}\n",
    "# Ensure same samples order in all matrices\n",
    "for pg in dn_pav:\n",
    "    dn_pav[pg].columns = [s.split('_')[0] for s in dn_pav[pg].columns]\n",
    "    dn_pav[pg] = dn_pav[pg][samples]\n",
    "    \n",
    "# Load MTP PAV matrices\n",
    "mtp_pav = {\n",
    "    pg :\n",
    "    pd.read_csv(os.path.join(mtp_pan_genomes[pg],\"all_samples/pan_genome/pan_PAV.tsv\"), sep='\\t', index_col='gene')\n",
    "    for pg in mtp_pan_genomes\n",
    "}\n",
    "# Ensure same samples order in all matrices\n",
    "for pg in mtp_pav:\n",
    "    mtp_pav[pg].columns = [s.split('_')[0] for s in mtp_pav[pg].columns]\n",
    "    mtp_pav[pg] = mtp_pav[pg][samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DN name matching\n",
    "dn_nonref_name_match = {pg:\n",
    "                        pd.read_csv(dn_compare[pg] + '/A_thaliana_DN_%s_vs_A_thaliana_DN_HQ_asm_max_weight_matches.tsv' % pg,\n",
    "                                    sep='\\t', index_col=0, header=0, usecols=[0,1], names=['orig_name','HQ_name'])\n",
    "                        for pg in dn_compare\n",
    "                       }\n",
    "\n",
    "# MTP name matching\n",
    "mtp_nonref_name_match = {pg:\n",
    "                        pd.read_csv(mtp_compare[pg] + '/A_thaliana_MTP_%s_vs_A_thaliana_MTP_HQ_asm_max_weight_matches.tsv' % pg,\n",
    "                                    sep='\\t', index_col=0, header=0, usecols=[0,1], names=['orig_name','HQ_name'])\n",
    "                        for pg in mtp_compare\n",
    "                       }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-metadata",
   "metadata": {},
   "source": [
    "### Calculate occupancy and occupancy class\n",
    "(core, shell, singleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occup_class(occup, core_cut):\n",
    "    if occup >= core_cut:\n",
    "        return 'Core'\n",
    "    elif occup == 1:\n",
    "        return 'Singleton'\n",
    "    else:\n",
    "        return 'Shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pg in dn_pav:\n",
    "    # calculate occupancy\n",
    "    dn_pav[pg]['occupancy'] = dn_pav[pg].apply(sum, axis=1)\n",
    "    # discard genes with occupancy 0\n",
    "    dn_pav[pg] = dn_pav[pg].query('occupancy > 0')\n",
    "    # occupancy class\n",
    "    dn_pav[pg]['occup_class'] = dn_pav[pg].apply(lambda row: occup_class(row['occupancy'], n_samples), axis=1)\n",
    "    \n",
    "for pg in mtp_pav:\n",
    "    # calculate occupancy\n",
    "    mtp_pav[pg]['occupancy'] = mtp_pav[pg].apply(sum, axis=1)\n",
    "    # discard genes with occupancy 0\n",
    "    mtp_pav[pg] = mtp_pav[pg].query('occupancy > 0')\n",
    "    # occupancy class\n",
    "    mtp_pav[pg]['occup_class'] = mtp_pav[pg].apply(lambda row: occup_class(row['occupancy'], n_samples), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-sitting",
   "metadata": {},
   "source": [
    "### Pan-genome size and composition\n",
    "Basic stats of the total sizes and occupancy classes of the various PGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_pg_composition = pd.concat([dn_pav[pg]['occup_class'].value_counts().rename(pg).sort_index()\n",
    "           for pg in pg_order], axis=1).transpose()\n",
    "dn_pg_composition['Total'] = dn_pg_composition.apply(sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtp_pg_composition = pd.concat([mtp_pav[pg]['occup_class'].value_counts().rename(pg).sort_index()\n",
    "           for pg in pg_order], axis=1).transpose()\n",
    "mtp_pg_composition['Total'] = mtp_pg_composition.apply(sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_composition = dn_pg_composition.join(mtp_pg_composition, rsuffix='_MTP')\n",
    "pg_composition.columns = pd.MultiIndex.from_product([['De novo','Map-to-pan'],['Core','Shell','Singletons','Total']])\n",
    "pg_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1,\n",
    "                    shared_xaxes=True,\n",
    "                    vertical_spacing=0.1,\n",
    "                   subplot_titles=('De novo', 'Map-to-pan'),\n",
    "                   y_title=\"Number of pan-genes\")\n",
    "\n",
    "fig.add_trace(go.Bar(x=dn_pg_composition.index, y=dn_pg_composition['Core'], name='Core', legendrank=3), row=1, col=1)\n",
    "fig.add_trace(go.Bar(x=dn_pg_composition.index, y=dn_pg_composition['Shell'], name='Shell', legendrank=2), row=1, col=1)\n",
    "fig.add_trace(go.Bar(x=dn_pg_composition.index, y=dn_pg_composition['Singleton'], name='Singleton', legendrank=1), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(x=mtp_pg_composition.index, y=mtp_pg_composition['Core'], name='Core', showlegend=False), row=2, col=1)\n",
    "fig.add_trace(go.Bar(x=mtp_pg_composition.index, y=mtp_pg_composition['Shell'], name='Shell', showlegend=False), row=2, col=1)\n",
    "fig.add_trace(go.Bar(x=mtp_pg_composition.index, y=mtp_pg_composition['Singleton'], name='Singleton', showlegend=False), row=2, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(barmode='stack', colorway=colors[2:])\n",
    "fig.update_xaxes(mirror=True, showline=True, linecolor='black')\n",
    "fig.update_yaxes(mirror=True, showline=True, linecolor='black', showgrid=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3_b = os.path.join(figs_path, 'fig3b.pdf')\n",
    "fig.write_image(fig3_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56277ec4-0ba8-4ff4-9e49-6d8630e5f336",
   "metadata": {},
   "source": [
    "### Per-sample number of genes\n",
    "Compare the number of genes detected as present per sample, across pan-genomes (increasing depth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed7b92-366a-49e9-9459-71314745668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate df\n",
    "dn_gene_counts = pd.concat([dn_pav[pg][samples].sum() for pg in pg_order], axis=1)\n",
    "dn_gene_counts.columns = pg_order\n",
    "mtp_gene_counts = pd.concat([mtp_pav[pg][samples].sum() for pg in pg_order], axis=1)\n",
    "mtp_gene_counts.columns = pg_order\n",
    "\n",
    "gene_counts = dn_gene_counts.join(mtp_gene_counts, rsuffix='MTP_')\n",
    "gene_counts.columns = pd.MultiIndex.from_product([['De novo','Map-to-pan'],pg_order])\n",
    "gene_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08076fa-8ab8-4b25-aad4-6fa2094a933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_gene_counts_melt = dn_gene_counts.reset_index().melt(id_vars='index', value_vars=pg_order)\n",
    "dn_gene_counts_melt.columns = ['sample','PG','count']\n",
    "mtp_gene_counts_melt = mtp_gene_counts.reset_index().melt(id_vars='index', value_vars=pg_order)\n",
    "mtp_gene_counts_melt.columns = ['sample','PG','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae055c3-fd3e-49c6-86c4-8a0cb2b4bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_gene_counts_melt['pipeline'] = 'De novo'\n",
    "mtp_gene_counts_melt['pipeline'] = 'Map-to-pan'\n",
    "gene_counts_melt = pd.concat([dn_gene_counts_melt,mtp_gene_counts_melt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d5c50-3248-4ee6-b8a7-f408fba11522",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbase = pd.Series(gene_counts_melt[\"PG\"].unique()).reset_index().rename(columns={\"index\":\"x\",0:\"PG\"})\n",
    "gene_counts_melt = gene_counts_melt.merge(xbase, on=\"PG\").set_index(\"pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77583245-efe4-4b10-9e00-2b1c1e4e7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples_color_map = dict(zip(gene_counts_melt['sample'].unique(), pio.templates['plotly'].layout.colorway[:8]))\n",
    "gene_counts_melt['color'] = gene_counts_melt.apply(lambda row: sample_colors[row['sample']], axis=1)\n",
    "\n",
    "pipeline_symbol_map = {'De novo': 'square',\n",
    "                      'Map-to-pan': 'cross'}\n",
    "gene_counts_melt['symbol'] = gene_counts_melt.apply(lambda row: pipeline_symbol_map[row.name], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d650e-5e2d-4e42-83d2-f83696c62786",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_gene_counts_median = dn_gene_counts_melt.groupby('PG').median()\n",
    "mtp_gene_counts_median = mtp_gene_counts_melt.groupby('PG').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd81e18-d8ed-477e-af28-bf2a7d4982d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_gene_counts_median = dn_gene_counts_median.merge(xbase, on='PG').sort_values('x')\n",
    "mtp_gene_counts_median = mtp_gene_counts_median.merge(xbase, on='PG').sort_values('x')\n",
    "mtp_gene_counts_median['x'] = mtp_gene_counts_median['x'] + 1/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0500102-98d7-4878-9cd4-854695e8fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    [\n",
    "        go.Scatter(\n",
    "            name=p,\n",
    "            x=gene_counts_melt.loc[p, \"x\"] + i/5,\n",
    "            y=gene_counts_melt.loc[p, \"count\"],\n",
    "            text=gene_counts_melt.loc[p, \"PG\"],\n",
    "            mode=\"markers\",\n",
    "            marker={\"color\": gene_counts_melt.loc[p, \"color\"], \"symbol\": gene_counts_melt.loc[p, \"symbol\"], \"size\":7},\n",
    "            hovertemplate=\"(%{text},%{y})\"\n",
    "        )\n",
    "        for i, p in enumerate(gene_counts_melt.index.get_level_values(\"pipeline\").unique())\n",
    "    ]\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=dn_gene_counts_median['x'], y=dn_gene_counts_median['count'],\n",
    "                    mode='lines',\n",
    "                    name='De novo Median',\n",
    "                    line={'color':'black','dash':'dash'}))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=mtp_gene_counts_median['x'], y=mtp_gene_counts_median['count'],\n",
    "                    mode='lines',\n",
    "                    name='Map-to-pan Median',\n",
    "                    line={'color':'darkgrey','dash':'dash'}))\n",
    "\n",
    "fig.update_layout(xaxis={\"tickmode\":\"array\", \"tickvals\":xbase[\"x\"], \"ticktext\":xbase[\"PG\"]},\n",
    "                 yaxis={'title': 'Number of genes'},\n",
    "                 )\n",
    "\n",
    "fig.update_xaxes(mirror=True, showline=True, linecolor='black')\n",
    "fig.update_yaxes(mirror=True, showline=True, linecolor='black', showgrid=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced959ee-b50d-4253-bd76-b69c6190efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3_c = os.path.join(figs_path, 'fig3c.pdf')\n",
    "fig.write_image(fig3_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbcf00e-20e2-4900-a022-60255a30131f",
   "metadata": {},
   "source": [
    "### Nonreference gene pool\n",
    "Analyze the effect of sequencing depth on the number of detected nonreference genes. Compare the nonreference pool of each pan-genome to that of the corresponding HQ pan-genome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c112daff-e880-4d38-9d6f-4590a2d908e5",
   "metadata": {},
   "source": [
    "#### Nonreference gene matching\n",
    "First, rename nonreference pan-genes according to their matching to the HQ pan-genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56b80e6-1840-420a-8c4a-4adaaf4e3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_nonref_name_match = {pg:\n",
    "                        pd.read_csv(dn_compare[pg] + '/A_thaliana_DN_%s_vs_A_thaliana_DN_HQ_asm_max_weight_matches.tsv' % pg.replace('-','_'), sep='\\t', index_col=0)\n",
    "                        for pg in pg_order[:-1]\n",
    "                       }\n",
    "\n",
    "mtp_nonref_name_match = {pg:\n",
    "                         pd.read_csv(mtp_compare[pg] + '/A_thaliana_MTP_%s_vs_A_thaliana_MTP_HQ_asm_max_weight_matches.tsv' % pg.replace('-','_'), sep='\\t', index_col=0)\n",
    "                         for pg in pg_order[:-1]\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc9c00-7221-447d-b4af-8690048bfaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gene_name(name, conv_df, pg_name):\n",
    "    if name.startswith('transcript'):\n",
    "        return name.replace(':','_')\n",
    "    if name in conv_df.index:\n",
    "        return conv_df.loc[name][0]\n",
    "    else:\n",
    "        return \"%s__%s_unmatched\" %(name, pg_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c733c69-bbd5-4fca-842a-e2632b78bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_name_match = {pg:\n",
    "                 dn_pav[pg].apply(lambda row: convert_gene_name(row.name, dn_nonref_name_match[pg], pg), axis=1)\n",
    "                 for pg in pg_order[:-1]\n",
    "                }\n",
    "\n",
    "mtp_name_match = {pg:\n",
    "                  mtp_pav[pg].apply(lambda row: convert_gene_name(row.name, mtp_nonref_name_match[pg], pg), axis=1)\n",
    "                  for pg in pg_order[:-1]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88318c67-1cfd-48b7-aee6-bf18dc233b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_pav_rename = {pg: dn_pav[pg].set_index(dn_pav[pg].index.map(dn_name_match[pg])) for pg in pg_order[:-1]}\n",
    "mtp_pav_rename = {pg: mtp_pav[pg].set_index(mtp_pav[pg].index.map(mtp_name_match[pg])) for pg in pg_order[:-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e79f31-c923-4600-846a-40f08e753dd9",
   "metadata": {},
   "source": [
    "#### Nonreference stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea4fa4-008c-41fc-bbfc-4c08df21891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many non-ref genes per PG and how many of these match HQ non-ref\n",
    "dn_nonref_matches = {pg:\n",
    "                     pd.read_csv(os.path.join(dn_compare[pg],\"A_thaliana_DN_%s_vs_A_thaliana_DN_HQ_asm_max_weight_matches.tsv\" % pg.replace('-','_')), sep='\\t')\n",
    "                     for pg in pg_order[:-1]\n",
    "                    }\n",
    "\n",
    "mtp_nonref_matches = {pg:\n",
    "                      pd.read_csv(os.path.join(mtp_compare[pg],\"A_thaliana_MTP_%s_vs_A_thaliana_MTP_HQ_asm_max_weight_matches.tsv\" % pg.replace('-','_')), sep='\\t')\n",
    "                      for pg in pg_order[:-1]\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499197aa-c68a-49aa-b066-ccd2eecee807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nonref(pg1_pav_df, pg2_pav_df, matches_df):\n",
    "    pg1_nonref = pg1_pav_df.index.str.startswith('PanGene').sum()\n",
    "    pg2_nonref = pg2_pav_df.index.str.startswith('PanGene').sum()\n",
    "    matched_nonref = matches_df.shape[0]\n",
    "    return (matched_nonref, pg1_nonref - matched_nonref, pg2_nonref - matched_nonref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b9d2e-db28-447f-92da-64ef2a042f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_nonref_counts = {pg:\n",
    "                    count_nonref(dn_pav[pg], dn_pav['HQ-assembly'], dn_nonref_matches[pg])\n",
    "                    for pg in pg_order[:-1]\n",
    "                   }\n",
    "\n",
    "mtp_nonref_counts = {pg:\n",
    "                     count_nonref(mtp_pav[pg], mtp_pav['HQ-assembly'], mtp_nonref_matches[pg])\n",
    "                     for pg in pg_order[:-1]\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc985c4a-7249-4901-8594-f45d561e4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_nonref_counts_df = pd.DataFrame.from_dict(dn_nonref_counts, orient='index')\n",
    "dn_nonref_counts_df.columns = ['Matched','PG+|HQ-','PG-|HQ+']\n",
    "dn_nonref_counts_df['Total nonref'] = dn_nonref_counts_df['Matched'] + dn_nonref_counts_df['PG+|HQ-'] + dn_nonref_counts_df['PG-|HQ+']\n",
    "\n",
    "mtp_nonref_counts_df = pd.DataFrame.from_dict(mtp_nonref_counts, orient='index')\n",
    "mtp_nonref_counts_df.columns = ['Matched','PG+|HQ-','PG-|HQ+']\n",
    "mtp_nonref_counts_df['Total nonref'] = mtp_nonref_counts_df['Matched'] + mtp_nonref_counts_df['PG+|HQ-'] + mtp_nonref_counts_df['PG-|HQ+']\n",
    "\n",
    "nonref_counts_df = dn_nonref_counts_df.join(mtp_nonref_counts_df, rsuffix='MTP_')\n",
    "nonref_counts_df.columns = pd.MultiIndex.from_product([['De novo','Map-to-pan'],dn_nonref_counts_df.columns])\n",
    "\n",
    "nonref_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d24111b-a7b3-408b-b929-894c117aa5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1,\n",
    "                    shared_xaxes=True,\n",
    "                    subplot_titles=(\"De novo\", \"Map-to-pan\"),\n",
    "                   vertical_spacing=0.1,\n",
    "                   y_title=\"Number of nonreference <br> pan-genes\")\n",
    "\n",
    "fig.add_trace(go.Bar(name='Matched', x=pg_order[:-1], y=[dn_nonref_counts[pg][0] for pg in pg_order[:-1]], legendgroup='matched', marker_color='darkseagreen'), row=1, col=1)    ,\n",
    "fig.add_trace(go.Bar(name='PG+|HQ-', x=pg_order[:-1], y=[dn_nonref_counts[pg][1] for pg in pg_order[:-1]], legendgroup='PG+|HQ-', marker_color='darkmagenta'), row=1, col=1)\n",
    "fig.add_trace(go.Bar(name='PG-|HQ+', x=pg_order[:-1], y=[dn_nonref_counts[pg][2] for pg in pg_order[:-1]], legendgroup='PG-|HQ+', marker_color='royalblue'), row=1, col=1)\n",
    "fig.add_trace(go.Bar(name='Matched', x=pg_order[:-1], y=[mtp_nonref_counts[pg][0] for pg in pg_order[:-1]], legendgroup='matched', showlegend=False, marker_color='darkseagreen'), row=2, col=1)    ,\n",
    "fig.add_trace(go.Bar(name='PG+|HQ-', x=pg_order[:-1], y=[mtp_nonref_counts[pg][1] for pg in pg_order[:-1]], legendgroup='PG+|HQ-', showlegend=False, marker_color='darkmagenta'), row=2, col=1)\n",
    "fig.add_trace(go.Bar(name='PG-|HQ+', x=pg_order[:-1], y=[mtp_nonref_counts[pg][2] for pg in pg_order[:-1]], legendgroup='PG-|HQ+', showlegend=False, marker_color='royalblue'), row=2, col=1)\n",
    "\n",
    "\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.update_xaxes(mirror=True, showline=True, linecolor='black')\n",
    "fig.update_yaxes(mirror=True, showline=True, linecolor='black', showgrid=False)\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5161d737-a6c0-4564-8187-b756056693e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3_d = os.path.join(figs_path, 'fig3d.pdf')\n",
    "fig.write_image(fig3_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d9947-e412-46d9-a280-ce776961d55c",
   "metadata": {},
   "source": [
    "#### Unmatched nonreference transcript mapping\n",
    "To better understand the origin of unmatched nonreference genes, transcripts of such genes were mapped to all  assemblies in the other pan-genome, and the number of transcripts that could not be mapped (95% transcript sequence coverage) to any assembly was calculated.  \n",
    "It is assumed that unmatched transcripts that could not be mapped originate from the absence of the relevant sequences in the assembly, whereas mapped transcripts indicate another source, e.g. gene duplications or clustering issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db65c61-9e76-46c5-9158-815c00e0e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mapping data\n",
    "dn_trans_mapping = {pg:[pd.read_csv(os.path.join(dn_compare[pg],\"A_thaliana_DN_%s_trans_vs_A_thaliana_DN_HQ_asm_assemblies/transcript_mapping.tsv\" % pg.replace('-','_')), sep='\\t'),\n",
    "                             pd.read_csv(os.path.join(dn_compare[pg],\"A_thaliana_DN_HQ_asm_trans_vs_A_thaliana_DN_%s_assemblies/transcript_mapping.tsv\" % pg.replace('-','_')), sep='\\t')]\n",
    "                        for pg in pg_order[:-1]}\n",
    "\n",
    "mtp_trans_mapping = {pg: [pd.read_csv(os.path.join(mtp_compare[pg],\"A_thaliana_MTP_%s_trans_vs_A_thaliana_MTP_HQ_asm_assemblies/transcript_mapping.tsv\" % pg.replace('-','_')), sep='\\t'),\n",
    "                             pd.read_csv(os.path.join(mtp_compare[pg],\"A_thaliana_MTP_HQ_asm_trans_vs_A_thaliana_MTP_%s_assemblies/transcript_mapping.tsv\" % pg.replace('-','_')), sep='\\t')]\n",
    "                        for pg in pg_order[:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b5c988-4201-4b5c-bca4-77142fe336da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \":\" in gene names with \"_\"\n",
    "for pg in mtp_trans_mapping:\n",
    "    mtp_trans_mapping[pg][0]['Query_sequence_name'] = mtp_trans_mapping[pg][0]['Query_sequence_name'].apply(lambda x: x.replace(':','_'))\n",
    "    mtp_trans_mapping[pg][1]['Query_sequence_name'] = mtp_trans_mapping[pg][1]['Query_sequence_name'].apply(lambda x: x.replace(':','_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b419fa8d-ec3e-4754-9301-404a5c344ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sets of nonreference gene names\n",
    "dn_pg_nonref = {pg:\n",
    "                set(dn_pav[pg].loc[dn_pav[pg].index.str.startswith('PanGene')].index)\n",
    "                for pg in pg_order\n",
    "               }\n",
    "\n",
    "mtp_pg_nonref = {pg:\n",
    "                set(mtp_pav[pg].loc[mtp_pav[pg].index.str.startswith('PanGene')].index)\n",
    "                for pg in pg_order\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b7b40-3e21-4a93-9e50-355ee18a2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of unmatched genrs\n",
    "dn_unmatched = {pg: [dn_pg_nonref[pg] - set(dn_nonref_matches[pg].iloc[:,1]),\n",
    "                    dn_pg_nonref['HQ-assembly'] - set(dn_nonref_matches[pg].iloc[:,2])] for pg in pg_order[:-1]}\n",
    "mtp_unmatched = {pg: [mtp_pg_nonref[pg] - set(mtp_nonref_matches[pg].iloc[:,1]),\n",
    "                    mtp_pg_nonref['HQ-assembly'] - set(mtp_nonref_matches[pg].iloc[:,2])] for pg in pg_order[:-1]}\n",
    "\n",
    "# Unmatched transcript mapping\n",
    "dn_unmatched_mapping = {pg:\n",
    "                        [dn_trans_mapping[pg][i].loc[dn_trans_mapping[pg][i]['Query_sequence_name'].isin(dn_unmatched[pg][i])] for i in range(2)]\n",
    "                        for pg in pg_order[:-1]\n",
    "                       }\n",
    "mtp_unmatched_mapping = {pg:\n",
    "                         [mtp_trans_mapping[pg][i].loc[mtp_trans_mapping[pg][i]['Query_sequence_name'].isin(mtp_unmatched[pg][i])] for i in range(2)]\n",
    "                         for pg in pg_order[:-1]\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2bae33-ce92-498f-b7c8-00b3beb1de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.95\n",
    "def is_mapped(x):\n",
    "    # x : chr1:100-500;0.92\n",
    "    if type(x) is float:\n",
    "        return np.nan\n",
    "    score = float(x.split(';')[1])\n",
    "    if score >= c:\n",
    "        return True\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "# return [# of mapped, # of unmapped]\n",
    "def unmatched_mapping(mapping_df):\n",
    "    tmp = mapping_df.set_index('Query_sequence_name')\n",
    "    tmp = tmp.applymap(is_mapped)\n",
    "    tmp = tmp.isnull().all(axis=1).value_counts()\n",
    "    return [tmp[False], tmp[True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80caa10a-9d0d-476d-bb3a-77d085e67130",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_unmatched_mapping_counts = {pg:\n",
    "                               [unmatched_mapping(dn_unmatched_mapping[pg][0]), unmatched_mapping(dn_unmatched_mapping[pg][1])]\n",
    "                               for pg in pg_order[:-1]\n",
    "                              }\n",
    "\n",
    "mtp_unmatched_mapping_counts = {pg:\n",
    "                                [unmatched_mapping(mtp_unmatched_mapping[pg][0]), unmatched_mapping(mtp_unmatched_mapping[pg][1])]\n",
    "                                for pg in pg_order[:-1]\n",
    "                               } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82a1ee-0d87-4fba-aeec-3c23d55f0c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "dn_unmatched_mapping_counts_df = pd.DataFrame.from_dict({k: flatten(dn_unmatched_mapping_counts[k]) for k in dn_unmatched_mapping_counts}, orient='index')\n",
    "dn_unmatched_mapping_counts_df.columns = ['PG+|HQ- - mapped','PG+|HQ- - unmapped','PG-|HQ+ - mapped','PG-|HQ+ - unmapped']\n",
    "\n",
    "mtp_unmatched_mapping_counts_df = pd.DataFrame.from_dict({k: flatten(mtp_unmatched_mapping_counts[k]) for k in mtp_unmatched_mapping_counts}, orient='index')\n",
    "mtp_unmatched_mapping_counts_df.columns = ['PG+|HQ- - mapped','PG+|HQ- - unmapped','PG-|HQ+ - mapped','PG-|HQ+ - unmapped']\n",
    "\n",
    "unmatched_mapping_counts_df = dn_unmatched_mapping_counts_df.join(mtp_unmatched_mapping_counts_df, rsuffix='MTP_')\n",
    "unmatched_mapping_counts_df.columns = pd.MultiIndex.from_product([['De novo','Map-to-pan'],dn_unmatched_mapping_counts_df.columns])\n",
    "\n",
    "unmatched_mapping_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16470534-a0ce-4136-aef3-c46252bf7aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    list(chain(*[[pg]*2 for pg in pg_order[:-1]])),\n",
    "    ['PG+|HQ-','PG-|HQ+']*len(pg_order)\n",
    "]\n",
    "y1 = list(chain(*[[dn_unmatched_mapping_counts[pg][0][0], dn_unmatched_mapping_counts[pg][1][0]] for pg in pg_order[:-1]]))\n",
    "y2 = list(chain(*[[dn_unmatched_mapping_counts[pg][0][1], dn_unmatched_mapping_counts[pg][1][1]] for pg in pg_order[:-1]]))\n",
    "fig = go.Figure()\n",
    "fig.add_bar(name=\"Mapped\", x=x, y=y1)\n",
    "fig.add_bar(name=\"Unmapped\", x=x, y=y2)\n",
    "fig.update_layout(barmode=\"relative\", title_text=\"De novo\")\n",
    "\n",
    "fig.update_yaxes(title_text=\"Number of nonreference <br> unmatched genes\")\n",
    "fig.update_xaxes(mirror=True, showline=True, linecolor='black')\n",
    "fig.update_yaxes(mirror=True, showline=True, linecolor='black', showgrid=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c6de7-2333-4bb0-b520-4c92ed5455a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = list(chain(*[[mtp_unmatched_mapping_counts[pg][0][0], mtp_unmatched_mapping_counts[pg][1][0]] for pg in pg_order[:-1]]))\n",
    "y2 = list(chain(*[[mtp_unmatched_mapping_counts[pg][0][1], mtp_unmatched_mapping_counts[pg][1][1]] for pg in pg_order[:-1]]))\n",
    "fig = go.Figure()\n",
    "fig.add_bar(name=\"Mapped\", x=x, y=y1)\n",
    "fig.add_bar(name=\"Unmapped\", x=x, y=y2)\n",
    "fig.update_layout(barmode=\"relative\", title_text=\"Map-to-pan\")\n",
    "\n",
    "fig.update_yaxes(title_text=\"Number of nonreference <br> unmatched genes\")\n",
    "fig.update_xaxes(mirror=True, showline=True, linecolor='black')\n",
    "fig.update_yaxes(mirror=True, showline=True, linecolor='black', showgrid=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3e3116-f7b3-4a53-9d78-8e83ef6a78de",
   "metadata": {},
   "source": [
    "### PAV discrepancies\n",
    "Compare PAV tables of each pan-genome to the corresponding HQ-assemblies pan-genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce896e1b-53ea-4642-91c1-079192e19c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate discrepancies tables\n",
    "\n",
    "# De novo discrepancies\n",
    "dn_pav_discrep = {}\n",
    "for pg in pg_order[:-1]:\n",
    "    # matched genes only\n",
    "    pg_pav_df = dn_pav_rename[pg].loc[~ dn_pav_rename[pg].index.str.endswith('_unmatched')]\n",
    "    hq_pav_df = dn_pav['HQ-assembly'].loc[pg_pav_df.index]\n",
    "    # find which genes are core in both\n",
    "    pg_core = set(pg_pav_df.query('occup_class == \"Core\"').index)\n",
    "    hq_core = set(hq_pav_df.query('occup_class == \"Core\"').index)\n",
    "    core_in_both = pg_core.intersection(hq_core)\n",
    "    pg_pav_df = pg_pav_df.loc[~pg_pav_df.index.isin(core_in_both)][samples]\n",
    "    hq_pav_df = hq_pav_df.loc[~hq_pav_df.index.isin(core_in_both)][samples]\n",
    "    # find discrepancies\n",
    "    discrep = pg_pav_df - hq_pav_df\n",
    "    dn_pav_discrep[pg] = discrep\n",
    "    \n",
    "# Map-to-pan discrepancies\n",
    "mtp_pav_discrep = {}\n",
    "for pg in pg_order[:-1]:\n",
    "    # matched genes only\n",
    "    pg_pav_df = mtp_pav_rename[pg].loc[~ mtp_pav_rename[pg].index.str.endswith('_unmatched')]\n",
    "    hq_pav_df = mtp_pav['HQ-assembly']\n",
    "    hq_pav_df.index = hq_pav_df.index.map(lambda x: x.replace(':','_'))\n",
    "    hq_pav_df = mtp_pav['HQ-assembly'].loc[pg_pav_df.index]\n",
    "    # find which genes are core in both\n",
    "    pg_core = set(pg_pav_df.query('occup_class == \"Core\"').index)\n",
    "    hq_core = set(hq_pav_df.query('occup_class == \"Core\"').index)\n",
    "    core_in_both = pg_core.intersection(hq_core)\n",
    "    pg_pav_df = pg_pav_df.loc[~pg_pav_df.index.isin(core_in_both)][samples]\n",
    "    hq_pav_df = hq_pav_df.loc[~hq_pav_df.index.isin(core_in_both)][samples]\n",
    "    # find discrepancies\n",
    "    discrep = pg_pav_df - hq_pav_df\n",
    "    mtp_pav_discrep[pg] = discrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b855251-63ad-4b1d-8e88-591de440ce5d",
   "metadata": {},
   "source": [
    "#### Total discrepancies and types\n",
    "How many discrepancies are there in each PG, and of what type (PG-|HQ+ vs. PG+|HQ-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01c5a9-a2e8-492a-be9d-7bc6489b618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DN\n",
    "dn_discrep_types = pd.concat([dn_pav_discrep[pg].apply(lambda row: row.value_counts(), axis=1).sum().loc[[-1,1]] for pg in pg_order[:-1]], axis=1)\n",
    "dn_discrep_types.index = ['PG-|HQ+','PG+|HQ-']\n",
    "dn_discrep_types.columns = pg_order[:-1]\n",
    "dn_discrep_types = dn_discrep_types.transpose()\n",
    "dn_discrep_types['Total discrepancies'] = dn_discrep_types.apply(sum, axis=1)\n",
    "dn_discrep_types['Total PA calls'] = [dn_pav_discrep[pg].shape[0] * dn_pav_discrep[pg].shape[1] for pg in pg_order[:-1]]\n",
    "dn_discrep_types['% Discrepancies'] = dn_discrep_types['Total discrepancies']/dn_discrep_types['Total PA calls']*100\n",
    "\n",
    "# MTP\n",
    "mtp_discrep_types = pd.concat([mtp_pav_discrep[pg].apply(lambda row: row.value_counts(), axis=1).sum().loc[[-1,1]] for pg in pg_order[:-1]], axis=1)\n",
    "mtp_discrep_types.index = ['PG-|HQ+','PG+|HQ-']\n",
    "mtp_discrep_types.columns = pg_order[:-1]\n",
    "mtp_discrep_types = mtp_discrep_types.transpose()\n",
    "mtp_discrep_types['Total discrepancies'] = mtp_discrep_types.apply(sum, axis=1)\n",
    "mtp_discrep_types['Total PA calls'] = [mtp_pav_discrep[pg].shape[0] * mtp_pav_discrep[pg].shape[1] for pg in pg_order[:-1]]\n",
    "mtp_discrep_types['% Discrepancies'] = mtp_discrep_types['Total discrepancies']/mtp_discrep_types['Total PA calls']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618b1ba-b521-4611-91d5-9c0a3d09c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrep_types = dn_discrep_types.join(mtp_discrep_types, rsuffix='_MTP')\n",
    "discrep_types.columns = pd.MultiIndex.from_product([['De novo','Map-to-pan'],dn_discrep_types.columns])\n",
    "discrep_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcb12c-48db-40d5-8878-a664f4f36598",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1,\n",
    "                    shared_xaxes=True,\n",
    "                    subplot_titles=(\"De novo\", \"Map-to-pan\"),\n",
    "                   vertical_spacing=0.1,\n",
    "                   y_title=\"Number of <br> PAV discrepancies\")\n",
    "\n",
    "fig.add_trace(go.Bar(name='PG-|HQ+', x=pg_order[:-1], y=dn_discrep_types['PG-|HQ+'], marker_color='grey'), row=1, col=1)\n",
    "fig.add_trace(go.Bar(name='PG+|HQ-', x=pg_order[:-1], y=dn_discrep_types['PG+|HQ-'], marker_color='black'), row=1, col=1)\n",
    "fig.add_trace(go.Bar(name='PG-|HQ+', x=pg_order[:-1], y=mtp_discrep_types['PG-|HQ+'], marker_color='grey', showlegend=False), row=2, col=1)\n",
    "fig.add_trace(go.Bar(name='PG+|HQ-', x=pg_order[:-1], y=mtp_discrep_types['PG+|HQ-'], marker_color='black', showlegend=False), row=2, col=1)\n",
    "\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.update_xaxes(mirror=True, showline=True, linecolor='black')\n",
    "fig.update_yaxes(mirror=True, showline=True, linecolor='black', showgrid=False)\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15b461-fb81-411f-a8d8-28f665b5b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3_e = os.path.join(figs_path, 'fig3e.pdf')\n",
    "fig.write_image(fig3_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588512b-a5d4-4b08-b860-bcc156db6357",
   "metadata": {},
   "source": [
    "#### Mapped/unmapped discrepancies\n",
    "To try and better understand the causes of discrepancies in gene PAV calling between pan-genomes, transcripts of genes detected as present in sample X in PG1, but absent in sample X in PG2 are searched in the genome assembly of sample X in PG2. Discrepancies are classified into \"mapped\" and \"unmapped\" based on whether or not they were found in the assembly. This is similar to the mapped/unmapped analysis performed for nonreference unmatched genes, but transcripts are only searched in the relevant assemblies.  \n",
    "Unmatched genes are ignored in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192122e-5abe-464e-9486-0d559948ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create melted discrepancies tables\n",
    "dn_pav_discrep_melt = {pg:\n",
    "                       dn_pav_discrep[pg].melt(value_vars=dn_pav_discrep[pg].columns, ignore_index=False, var_name='sample', value_name='type').query('type != 0')\n",
    "                       for pg in pg_order[:-1]\n",
    "                      }\n",
    "\n",
    "mtp_pav_discrep_melt = {pg:\n",
    "                       mtp_pav_discrep[pg].melt(value_vars=mtp_pav_discrep[pg].columns, ignore_index=False, var_name='sample', value_name='type').query('type != 0')\n",
    "                       for pg in pg_order[:-1]\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f3386-10a5-45b0-a6bc-3215297699f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join discrepancies tables with transcript mappings\n",
    "# {pg: [PG-/HQ+ discrepancies, PG+/HQ- discrepancies]}\n",
    "dn_discrep_trans_mapping = {pg :\n",
    "                            [dn_pav_discrep_melt[pg].query(\"type == -1\").merge(dn_trans_mapping[pg][1], left_on='gene', right_on='Query_sequence_name'),\n",
    "                            dn_pav_discrep_melt[pg].query(\"type == 1\").merge(dn_trans_mapping[pg][0], left_on='gene', right_on='Query_sequence_name')]\n",
    "                           for pg in pg_order[:-1]}\n",
    "\n",
    "mtp_discrep_trans_mapping = {pg :\n",
    "                            [mtp_pav_discrep_melt[pg].query(\"type == -1\").merge(mtp_trans_mapping[pg][1], left_on='gene', right_on='Query_sequence_name'),\n",
    "                            mtp_pav_discrep_melt[pg].query(\"type == 1\").merge(mtp_trans_mapping[pg][0], left_on='gene', right_on='Query_sequence_name')]\n",
    "                           for pg in pg_order[:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc6195-00e1-4b7c-beed-53cb3bb80f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_mapped(row):\n",
    "    sample = row['sample']\n",
    "    if type(row[sample]) is float:\n",
    "        return False\n",
    "    score = float(row[sample].split(';')[1])\n",
    "    if score > c:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def count_mapped_discrep(df):\n",
    "    df['Mapped'] = df.apply(trans_mapped, axis=1)\n",
    "    mapped_count = df['Mapped'].value_counts()\n",
    "    for val in [True, False]:\n",
    "        if val not in mapped_count:\n",
    "            mapped_count = mapped_count.append(pd.Series([0], index=[val]))\n",
    "    return [mapped_count[True], mapped_count[False]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8889cce-7cb6-4323-83cc-d9c27e9e10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {pg: [[PG-/HQ+ mapped, PG-/HQ+ unmapped], [PG+/HQ- mapped, PG+/HQ- unmapped] ]}\n",
    "dn_discrep_trans_mapped_count = {pg :\n",
    "                                 [count_mapped_discrep(dn_discrep_trans_mapping[pg][0]),\n",
    "                                  count_mapped_discrep(dn_discrep_trans_mapping[pg][1])]\n",
    "                                 for pg in pg_order[:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb940f0-d8e3-4234-9230-02a40d63410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtp_discrep_trans_mapped_count = {pg :\n",
    "                                 [count_mapped_discrep(mtp_discrep_trans_mapping[pg][0]),\n",
    "                                  count_mapped_discrep(mtp_discrep_trans_mapping[pg][1])]\n",
    "                                 for pg in pg_order[:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35aa189-124e-4316-a70e-8eb8f4b155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_discrep_trans_mapped_count_df = pd.DataFrame([list(chain(*dn_discrep_trans_mapped_count[pg])) for pg in pg_order[:-1]])\n",
    "dn_discrep_trans_mapped_count_df.index = pg_order[:-1]\n",
    "dn_discrep_trans_mapped_count_df.columns = pd.MultiIndex.from_product([['De novo'],['PG-/HQ+','PG+/HQ-'],['Mapped','Unmapped']])\n",
    "\n",
    "mtp_discrep_trans_mapped_count_df = pd.DataFrame([list(chain(*mtp_discrep_trans_mapped_count[pg])) for pg in pg_order[:-1]])\n",
    "mtp_discrep_trans_mapped_count_df.index = pg_order[:-1]\n",
    "mtp_discrep_trans_mapped_count_df.columns = pd.MultiIndex.from_product([['Map-to-pan'],['PG-/HQ+','PG+/HQ-'],['Mapped','Unmapped']])\n",
    "\n",
    "discrep_trans_mapped_count_df = dn_discrep_trans_mapped_count_df.join(mtp_discrep_trans_mapped_count_df, rsuffix='MTP_')\n",
    "discrep_trans_mapped_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aebaa5-b5c0-42cb-9c56-8fe86bf5449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    list(chain(*[[pg]*2 for pg in pg_order[:-1]])),\n",
    "    ['PG+|HQ-','PG-|HQ+']*len(pg_order)\n",
    "]\n",
    "y1 = list(chain(*[[dn_discrep_trans_mapped_count[pg][0][0], dn_discrep_trans_mapped_count[pg][1][0]] for pg in pg_order[:-1]]))\n",
    "y2 = list(chain(*[[dn_discrep_trans_mapped_count[pg][0][1], dn_discrep_trans_mapped_count[pg][1][1]] for pg in pg_order[:-1]]))\n",
    "fig = go.Figure()\n",
    "fig.add_bar(name=\"Mapped\", x=x, y=y1)\n",
    "fig.add_bar(name=\"Unmapped\", x=x, y=y2)\n",
    "fig.update_layout(barmode=\"relative\", title_text=\"De novo\")\n",
    "\n",
    "fig.update_yaxes(title_text=\"Number of discrepancies\")\n",
    "fig.update_xaxes(mirror=True, showline=True, linecolor='black')\n",
    "fig.update_yaxes(mirror=True, showline=True, linecolor='black', showgrid=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c7a463-0384-4199-8bac-5ec47da9efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = list(chain(*[[mtp_discrep_trans_mapped_count[pg][0][0], mtp_discrep_trans_mapped_count[pg][1][0]] for pg in pg_order[:-1]]))\n",
    "y2 = list(chain(*[[mtp_discrep_trans_mapped_count[pg][0][1], mtp_discrep_trans_mapped_count[pg][1][1]] for pg in pg_order[:-1]]))\n",
    "fig = go.Figure()\n",
    "fig.add_bar(name=\"Mapped\", x=x, y=y1)\n",
    "fig.add_bar(name=\"Unmapped\", x=x, y=y2)\n",
    "fig.update_layout(barmode=\"relative\", title_text=\"Map-to-pan\")\n",
    "\n",
    "fig.update_yaxes(title_text=\"Number of discrepancies\")\n",
    "fig.update_xaxes(mirror=True, showline=True, linecolor='black')\n",
    "fig.update_yaxes(mirror=True, showline=True, linecolor='black', showgrid=False)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
